{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWYbyNlKOWkA38+MD3KDPv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hackveda/PythonInternsCodeSubmission/blob/main/thasneemkp/build_a_digital_marketing_tool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyrBW4zO5dGf"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import json\n",
        "from datetime import date, timedelta\n",
        "today = date.today()\n",
        "yesterday = today - timedelta(days=1)\n",
        "\n",
        "def make_clickable_both(val):\n",
        "    name, url = val.split('#')\n",
        "    return f'<a href=\"{url}\">{name}</a>'\n",
        "\n",
        "   keyword = iput (\"search a keyword \")\n",
        "\n",
        "   oogle_url =\n",
        "\n",
        "def searchRequest(start=\"1\"):\n",
        "  search_request =google_url + \"6q=\" + keyword + \"6start=\"+start\n",
        "  return search_request\n",
        "\n",
        "response = requests.get(searchRequest())\n",
        "\n",
        "json_response = json.loads(response.text)\n",
        "\n",
        "total_results = int(json_response[\"searchInformation\"][\"totalResults\"])\n",
        "next_index = int(json_response[\"queries\"][\"nextPage\"][0][\"startIndex\"])\n",
        "total_pages = round(total_results / 10)\n",
        "\n",
        "college_data = {}\n",
        "l_title = []\n",
        "l_url = []\n",
        "l_htmlsnipper = []\n",
        "try:\n",
        "  while next_index < total_pages:\n",
        "    for item in json_response[\"items\"]:\n",
        "      url = item[\"link\"].replace(\"\",\"\")\n",
        "      url = f'<a href='\"{url}\">{url}</a>'\n",
        "      l_url.append(url)\n",
        "      l_title.append(item[\"title\"],replace(\"\",\"\"))\n",
        "      l_htmlsnippet.append(item[\"htmlsnippet\"],replace(\"\",\"\"))\n",
        "    response = requests.get(searchRequest(start=str(next_index)))[\"startindex\"]\n",
        "    json_response = json.loads(response.text)\n",
        "\n",
        "    next_index = json_response[\"queries\"][\"nextpage\"][e][\"startIndex\"]\n",
        "\n",
        "except:\n",
        "   print(\"search Complete Exception\")\n",
        "college_data[\"Title\"] = l_title\n",
        "college_data[\"Url\"] = l_url\n",
        "college_data[\"Htmlsnippet\"] = l_htmlSnippet\n",
        "\n",
        "alldata = pd.Dataframe(data=college_data)\n",
        "print(\"Data collected for %d links\" % alldata.shape[0])\n",
        "\n",
        "alldata.reset_index().style.format({'url': make_clickable_both})\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}