{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-LPxQuOkiyBS",
        "outputId": "d3b472dc-abbd-473e-a391-b85ad8cdd481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/deanmalmgren/textract\n",
            "  Cloning https://github.com/deanmalmgren/textract to /tmp/pip-req-build-88n2coah\n",
            "  Running command git clone -q https://github.com/deanmalmgren/textract /tmp/pip-req-build-88n2coah\n",
            "Collecting argcomplete~=1.10.0\n",
            "  Downloading argcomplete-1.10.3-py2.py3-none-any.whl (36 kB)\n",
            "Collecting beautifulsoup4~=4.8.0\n",
            "  Downloading beautifulsoup4-4.8.2-py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 13.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from textract==1.6.5) (3.0.4)\n",
            "Collecting docx2txt~=0.8\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "Collecting extract-msg<=0.29.*\n",
            "  Downloading extract_msg-0.28.7-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 6.7 MB/s \n",
            "\u001b[?25hCollecting pdfminer.six==20191110\n",
            "  Downloading pdfminer.six-20191110-py2.py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 51.2 MB/s \n",
            "\u001b[?25hCollecting python-pptx~=0.6.18\n",
            "  Downloading python-pptx-0.6.21.tar.gz (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 50.5 MB/s \n",
            "\u001b[?25hCollecting six~=1.12.0\n",
            "  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting SpeechRecognition~=3.8.1\n",
            "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8 MB 1.5 MB/s \n",
            "\u001b[?25hCollecting xlrd~=1.2.0\n",
            "  Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 62.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pdfminer.six==20191110->textract==1.6.5) (2.4.0)\n",
            "Collecting pycryptodome\n",
            "  Downloading pycryptodome-3.15.0-cp35-abi3-manylinux2010_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 58.3 MB/s \n",
            "\u001b[?25hCollecting soupsieve>=1.2\n",
            "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
            "Collecting tzlocal>=2.1\n",
            "  Downloading tzlocal-4.2-py3-none-any.whl (19 kB)\n",
            "Collecting compressed-rtf>=1.0.6\n",
            "  Downloading compressed_rtf-1.0.6.tar.gz (5.8 kB)\n",
            "Collecting imapclient==2.1.0\n",
            "  Downloading IMAPClient-2.1.0-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting olefile>=0.46\n",
            "  Downloading olefile-0.46.zip (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 65.5 MB/s \n",
            "\u001b[?25hCollecting ebcdic>=1.1.1\n",
            "  Downloading ebcdic-1.1.1-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 58.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from python-pptx~=0.6.18->textract==1.6.5) (4.9.1)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.7/dist-packages (from python-pptx~=0.6.18->textract==1.6.5) (7.1.2)\n",
            "Collecting XlsxWriter>=0.5.7\n",
            "  Downloading XlsxWriter-3.0.3-py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 47.0 MB/s \n",
            "\u001b[?25hCollecting backports.zoneinfo\n",
            "  Downloading backports.zoneinfo-0.2.1-cp37-cp37m-manylinux1_x86_64.whl (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 8.2 MB/s \n",
            "\u001b[?25hCollecting pytz-deprecation-shim\n",
            "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tzdata\n",
            "  Downloading tzdata-2022.2-py2.py3-none-any.whl (336 kB)\n",
            "\u001b[K     |████████████████████████████████| 336 kB 62.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: textract, docx2txt, compressed-rtf, olefile, python-pptx\n",
            "  Building wheel for textract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for textract: filename=textract-1.6.5-py3-none-any.whl size=23140 sha256=6e7ea05d3775631a0529e9d0edaebae2a58d934ef7ba8c72cc98adb9d58b07dc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-x1di04uf/wheels/1b/10/32/71c9f6007c205a6c1c47735bf9c0e73575bdcf98716390b25d\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3980 sha256=7085354eb3ca49b9aad29612cc23cebdd493835fa799b870d286c13a9268ca10\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/20/b2/473e3aea9a0c0d3e7b2f7bd81d06d0794fec12752733d1f3a8\n",
            "  Building wheel for compressed-rtf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for compressed-rtf: filename=compressed_rtf-1.0.6-py3-none-any.whl size=6204 sha256=d96a8d22c5fbef057d7add7da5d2bcf45afc3a2f17b200bd3fbc6a97b189d760\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/33/88/88ceee84d1b74b391c086bc594d3fcf80800decfbd6e1ff565\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35432 sha256=ecfed3dc307aabdda336730d7908569fc7a985b9601341589d84fafa8529da12\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/53/e6/37d90ccb3ad1a3ca98d2b17107e9fda401a7c541ea1eb6a65a\n",
            "  Building wheel for python-pptx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-pptx: filename=python_pptx-0.6.21-py3-none-any.whl size=470951 sha256=185e53172d7f2e91ea8ff16c89139b24fec1726d72db9e322b605f70d13176e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/ab/f4/52560d0d4bd4055e9261c6df6e51c7b56c2b23cca3dee811a3\n",
            "Successfully built textract docx2txt compressed-rtf olefile python-pptx\n",
            "Installing collected packages: tzdata, backports.zoneinfo, six, pytz-deprecation-shim, XlsxWriter, tzlocal, soupsieve, pycryptodome, olefile, imapclient, ebcdic, compressed-rtf, xlrd, SpeechRecognition, python-pptx, pdfminer.six, extract-msg, docx2txt, beautifulsoup4, argcomplete, textract\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: tzlocal\n",
            "    Found existing installation: tzlocal 1.5.1\n",
            "    Uninstalling tzlocal-1.5.1:\n",
            "      Successfully uninstalled tzlocal-1.5.1\n",
            "  Attempting uninstall: xlrd\n",
            "    Found existing installation: xlrd 1.1.0\n",
            "    Uninstalling xlrd-1.1.0:\n",
            "      Successfully uninstalled xlrd-1.1.0\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "google-api-python-client 1.12.11 requires six<2dev,>=1.13.0, but you have six 1.12.0 which is incompatible.\n",
            "google-api-core 1.31.6 requires six>=1.13.0, but you have six 1.12.0 which is incompatible.\u001b[0m\n",
            "Successfully installed SpeechRecognition-3.8.1 XlsxWriter-3.0.3 argcomplete-1.10.3 backports.zoneinfo-0.2.1 beautifulsoup4-4.8.2 compressed-rtf-1.0.6 docx2txt-0.8 ebcdic-1.1.1 extract-msg-0.28.7 imapclient-2.1.0 olefile-0.46 pdfminer.six-20191110 pycryptodome-3.15.0 python-pptx-0.6.21 pytz-deprecation-shim-0.1.0.post0 six-1.12.0 soupsieve-2.3.2.post1 textract-1.6.5 tzdata-2022.2 tzlocal-4.2 xlrd-1.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (0.2.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from moviepy) (1.21.6)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (2.9.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (4.64.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio<3.0,>=2.1.2->moviepy) (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyPdf2\n",
            "  Downloading PyPDF2-2.10.2-py3-none-any.whl (214 kB)\n",
            "\u001b[K     |████████████████████████████████| 214 kB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from PyPdf2) (4.1.1)\n",
            "Installing collected packages: PyPdf2\n",
            "Successfully installed PyPdf2-2.10.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gTTS\n",
            "  Downloading gTTS-2.2.4-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from gTTS) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gTTS) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gTTS) (1.12.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gTTS) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gTTS) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gTTS) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gTTS) (1.24.3)\n",
            "Installing collected packages: gTTS\n",
            "Successfully installed gTTS-2.2.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pdf2jpg\n",
            "  Downloading pdf2jpg-1.1-py3-none-any.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 7.2 MB/s \n",
            "\u001b[?25hCollecting img2pdf\n",
            "  Downloading img2pdf-0.4.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from img2pdf->pdf2jpg) (7.1.2)\n",
            "Collecting pikepdf\n",
            "  Downloading pikepdf-5.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 44.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.0 in /usr/local/lib/python3.7/dist-packages (from pikepdf->img2pdf->pdf2jpg) (4.9.1)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.7/dist-packages (from pikepdf->img2pdf->pdf2jpg) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata>=4 in /usr/local/lib/python3.7/dist-packages (from pikepdf->img2pdf->pdf2jpg) (4.12.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pikepdf->img2pdf->pdf2jpg) (21.3)\n",
            "Collecting deprecation\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4->pikepdf->img2pdf->pdf2jpg) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pikepdf->img2pdf->pdf2jpg) (3.0.9)\n",
            "Building wheels for collected packages: img2pdf\n",
            "  Building wheel for img2pdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for img2pdf: filename=img2pdf-0.4.4-py3-none-any.whl size=44881 sha256=a3a503e8e0e35977aa98e00bb8df18d473f4bc2cdc34d205137c90e24201afa3\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/a7/53/9983aef9861f91881984e08f376e3119bdfeeecf55bd36e585\n",
            "Successfully built img2pdf\n",
            "Installing collected packages: deprecation, pikepdf, img2pdf, pdf2jpg\n",
            "Successfully installed deprecation-2.1.0 img2pdf-0.4.4 pdf2jpg-1.1 pikepdf-5.4.2\n",
            "Found existing installation: imageio 2.9.0\n",
            "Uninstalling imageio-2.9.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/imageio_download_bin\n",
            "    /usr/local/bin/imageio_remove_bin\n",
            "    /usr/local/lib/python3.7/dist-packages/imageio-2.9.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/imageio/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled imageio-2.9.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting imageio==2.4.1\n",
            "  Downloading imageio-2.4.1.tar.gz (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 10.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio==2.4.1) (1.21.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio==2.4.1) (7.1.2)\n",
            "Building wheels for collected packages: imageio\n",
            "  Building wheel for imageio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imageio: filename=imageio-2.4.1-py3-none-any.whl size=3303885 sha256=f8c2aeb07892e354d216629bd237b712cb380e9ffe77cdea1b930d60c7a51eca\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/20/07/7bb9c8c44e6ec2efa60fd0e6280094f53f65f41767ef69a5ee\n",
            "Successfully built imageio\n",
            "Installing collected packages: imageio\n",
            "Successfully installed imageio-2.4.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install git+https://github.com/deanmalmgren/textract\n",
        "\n",
        "\n",
        "!pip install opencv-python\n",
        "!pip install moviepy\n",
        "!pip install PyPdf2\n",
        "!pip install gTTS\n",
        "!pip install pdf2jpg\n",
        "!pip uninstall imageio\n",
        "!pip install \"imageio==2.4.1\"\n",
        "\n",
        "import nltk \n",
        "nltk.download(\"popular\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize  \n",
        "import string                            \n",
        "from pdf2jpg import pdf2jpg\n",
        "import os, sys, stat\n",
        "from gtts import gTTS\n",
        "import cv2 \n",
        "from PIL import Image                             \n",
        "from os import walk \n",
        "import moviepy.editor as mpe"
      ],
      "metadata": {
        "id": "id6VpVq3jRtu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b3e9334-4451-4dff-96c7-39630d1a937c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2809856/45929032 bytes (6.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b6168576/45929032 bytes (13.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b9404416/45929032 bytes (20.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b12722176/45929032 bytes (27.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16039936/45929032 bytes (34.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b19128320/45929032 bytes (41.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b22536192/45929032 bytes (49.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b25870336/45929032 bytes (56.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b28999680/45929032 bytes (63.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b32210944/45929032 bytes (70.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b35356672/45929032 bytes (77.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b38273024/45929032 bytes (83.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b41246720/45929032 bytes (89.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b44220416/45929032 bytes (96.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def makeAudio(pagetext, page_no): \n",
        "  text = remove_punctuations_audio(pagetext)  \n",
        "  print(text) \n",
        "  tts = gTTS(text=text, lang=\"en\", tld=\"co.in\", slow=False)\n",
        "  filename = \"page_\"+ str(page_no) + '.mp3'\n",
        "  os.chdir(path_audio)\n",
        "  tts.save(filename)\n",
        "\n",
        "\n",
        "def remove_punctuations_audio(text):\n",
        "  words = nltk.word_tokenize(text)  \n",
        "  punct = \"!\\\"#$&();<>[\\\\]^{|}~_\"\n",
        "  punt_removed = [w for w in words if w.lower() not in punct]\n",
        "  return \" \".join(punt_removed)\n",
        "\n",
        "\n",
        "def createImage(page_no, inputpath, outputpath):\n",
        "  imageList = []\n",
        "  result = pdf2jpg.convert_pdf2jpg(inputpath, outputpath,  pages=str(page_no))\n",
        "  print(\"CreateImage result\", result)\n",
        "  return imageList.append(str(page_no)+\"_\"+doc_name+\".jpg\")\n",
        "\n",
        "\n",
        "def generate_video(page_no, files): \n",
        "  image_folder = path_resized+\"/\"+str(page_no)\n",
        "  video_name = path_video + \"/\"+str(page_no)+'.mp4'\n",
        "\n",
        "\n",
        "  images = [img for img in files \n",
        "            if img.endswith(\".jpg\") or\n",
        "               img.endswith(\".jpeg\") or\n",
        "               img.endswith(\"png\")] \n",
        "    \n",
        "  frame = cv2.imread(os.path.join(image_folder, images[0])) \n",
        "\n",
        "\n",
        "  height, width, layers = frame.shape   \n",
        "\n",
        "  video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'DIVX'), 60, (width, height)) \n",
        "\n",
        "  \n",
        "  for image in images:  \n",
        "      print(\"Adding \", image, \" to video\")\n",
        "      img = cv2.imread(os.path.join(image_folder, image))\n",
        "      cv2.putText(img, \"hackveda.in\", (width - 150, round(height / 8)), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), lineType=cv2.LINE_AA)\n",
        "      video.write(img)         \n",
        " \n",
        "  cv2.destroyAllWindows()  \n",
        "  video.release() \n",
        "  print(\"Video ready\", video_name)\n",
        "\n",
        "\n",
        "def makeCourseVideo(imagePath, page_no):\n",
        "  path = imagePath\n",
        "  mean_height = 0\n",
        "  mean_width = 0\n",
        "  files= []\n",
        "  for (dirpath, dirnames, filenames) in walk(path_images+\"/\"+doc_name+\"_dir\"):\n",
        "    files.extend(filenames)\n",
        "    break\n",
        "  print(files)\n",
        "\n",
        "  num_of_images = len(files)\n",
        "\n",
        "\n",
        "  for file in files: \n",
        "    try:\n",
        "      print(\"Test\", file)\n",
        "      im = Image.open(os.path.join(path, file)) \n",
        "      width, height = im.size \n",
        "      mean_width += width \n",
        "      mean_height += height \n",
        "    except:\n",
        "      print(\"Image Exception\")\n",
        "  mean_width = int(mean_width / num_of_images) \n",
        "  mean_height = int(mean_height / num_of_images) \n",
        "  for file in files: \n",
        "    try:\n",
        "      if file.endswith(\".jpg\") or file.endswith(\".jpeg\") or file.endswith(\"png\"): \n",
        "        im = Image.open(os.path.join(path, file))\n",
        "\n",
        "        width, height = im.size    \n",
        "        print(width, height) \n",
        "\n",
        "        # resizing  \n",
        "        imResize = im.resize((mean_width, mean_height), Image.ANTIALIAS)  \n",
        "        imResize.save(path_resized + \"/\" + str(page_no) + \"/\" + file, 'JPEG', quality = 95)\n",
        "        \n",
        "        print(im.filename.split('\\\\')[-1], \" is resized\")  \n",
        "         \n",
        "        \n",
        "    except:\n",
        "      print(\"Image Exception\")\n",
        " \n",
        "  generate_video(page_no, files)\n",
        "\n",
        "\n",
        "def makeProductionVideo(path_final, page_no):\n",
        "  my_clip = mpe.VideoFileClip(path_video+\"/\"+str(page_no)+'.mp4')\n",
        "  audio_background = mpe.AudioFileClip(path_audio+\"/page_\"+str(page_no)+'.mp3')\n",
        "  final_audio = mpe.CompositeAudioClip([audio_background])\n",
        "  final_clip = my_clip.set_audio(final_audio)\n",
        "\n",
        "  final_clip.write_videofile(path_final+\"/\" + \"Lesson \" + str(page_no + 1)+ \"-\" + course + \".mp4\", audio_codec=\"aac\")"
      ],
      "metadata": {
        "id": "8C-fZz9hjiFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2 \n",
        "import textract\n",
        "\n",
        "doc_name = \"sample.pdf\"\n",
        "\n",
        "pdfFileObj = open(\"/content/\"+doc_name, 'rb') \n",
        "\n",
        "\n",
        "pdfReader = PyPDF2.PdfFileReader(pdfFileObj) \n",
        "  \n",
        "\n",
        "number_of_pages = pdfReader.numPages\n",
        "print(\"Number of pages\", number_of_pages)\n",
        "\n",
        "page_no = 0\n",
        "\n",
        "course = input(\"Enter course transcript name: \")\n",
        "path = \"/content/\"+course\n",
        "path_transcript = path + \"/transcript\"\n",
        "\n",
        "os.mkdir(path)\n",
        "os.mkdir(path_transcript)\n",
        "\n",
        "startpage = int(input(\"Enter start page no:\"))\n",
        "endpage = int(input(\"Enter end page no:\"))\n",
        "\n",
        "while(page_no < number_of_pages):\n",
        "  if page_no >= startpage and page_no <= endpage:\n",
        "    pagetext = \"\"\n",
        "    pageObj = pdfReader.getPage(page_no)\n",
        "    print(\"Reading page number\", page_no)\n",
        "    pagetext = pagetext + \" \" + pageObj.extractText() \n",
        "\n",
        "    if pagetext.strip() == \"\":\n",
        "      pdfwriter = PyPDF2.PdfFileWriter()\n",
        "      pdfwriter.addPage(pdfReader.getPage(page_no))\n",
        "      with open('/content/sample.pdf', 'wb') as f:\n",
        "        pdfwriter.write(f)\n",
        "        f.close()\n",
        "      pagetext = textract.process(\"/content/sample.pdf\").decode(\"UTF-8\")\n",
        "\n",
        "    pagetext = remove_punctuations_audio(pagetext)\n",
        "    \n",
        "    transfile = open(path_transcript + \"/\" + str(page_no) + \".txt\", 'w')  \n",
        "    print(pagetext, file=transfile, flush=True)  \n",
        "  page_no += 1"
      ],
      "metadata": {
        "id": "rJahcboydBd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb66ef9e-fbcd-427e-90e8-abcd7faff7ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of pages 2\n",
            "Enter course transcript name: Tus\n",
            "Enter start page no:0\n",
            "Enter end page no:5\n",
            "Reading page number 0\n",
            "Reading page number 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#doc_name = \"sample.pdf\"\n",
        "pdfFileObj = open(\"/content/\"+doc_name, 'rb') \n",
        "  \n",
        "\n",
        "pdfReader = PyPDF2.PdfFileReader(pdfFileObj) \n",
        "  \n",
        "\n",
        "number_of_pages = pdfReader.numPages\n",
        "print(number_of_pages)\n",
        "pagetext_list = []\n",
        "\n",
        "page_no = 0\n",
        "start_page = page_no\n",
        "last_page = number_of_pages - 1\n",
        "\n",
        "course = input(\"Enter course name: \")\n",
        "path = \"/content/\"+course\n",
        "path_images = path +\"/images\"\n",
        "path_resized = path +\"/resized\"\n",
        "path_audio = path +\"/audio\"\n",
        "path_video = path +\"/video\"\n",
        "path_final = path + \"_final\"\n",
        "\n",
        "\n",
        "os.mkdir(path)\n",
        "os.mkdir(path_images)\n",
        "os.mkdir(path_resized)\n",
        "os.mkdir(path_audio)\n",
        "os.mkdir(path_video)\n",
        "os.mkdir(path_final)\n",
        "\n",
        "os.chmod(path_images, stat.S_IRWXO)\n",
        "os.chmod(path_video, 777)\n",
        "os.chmod(path_final, 777)\n",
        "\n",
        "while(page_no < number_of_pages):\n",
        "  if page_no >= startpage and page_no <= endpage:\n",
        "    pagetext = \"\" \n",
        "    pageObj = pdfReader.getPage(page_no)\n",
        "\n",
        "    \n",
        "    t_file = open(path_transcript + \"/\" + str(page_no) +\".txt\", \"r\")\n",
        "    pagetext = t_file.read()\n",
        "    if page_no == start_page:\n",
        "      pagetext = \"Hi, I am Tushar from Hackveda. In this video i have brought to you, \" + pagetext\n",
        "    \n",
        "    if page_no == last_page:\n",
        "      pagetext = pagetext + \"Thanks for watching. See you in the next video.\"\n",
        "\n",
        "  \n",
        "    \n",
        "    print(pagetext)\n",
        "    \n",
        "\n",
        "\n",
        "    try:\n",
        "      makeAudio(pagetext, page_no) \n",
        "    except Exception as e:\n",
        "      makeAudio(pagetext, page_no) \n",
        "      print(\"Exception audio:\", e)\n",
        "    imageCounter = 1\n",
        "    \n",
        "    imageList = createImage(page_no, \"/content/\"+doc_name, path_images)\n",
        "    print(imageList)\n",
        "      \n",
        "   \n",
        "    os.mkdir(path_resized+\"/\"+str(page_no))\n",
        "\n",
        "    makeCourseVideo(path_images + \"/\" + doc_name+\"_dir\", page_no)\n",
        "  \n",
        "    makeProductionVideo(path_final, page_no)\n",
        "    \n",
        "\n",
        "  page_no = page_no + 1\n",
        "      \n",
        "\n",
        "pdfFileObj.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4Inb6vm8yal",
        "outputId": "7d8743e4-d08a-4ca2-d9b6-a185b808ac18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "Enter course name: Tushar\n",
            "Hi, I am Tushar from Hackveda. In this video i have brought to you, A Simple PDF File This is a small demonstration .pdf file - just for use in the Virtual Mechanics tutorials . More text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . Boring , zzzzz . And more text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . Even more . Continued on page 2 ...\n",
            "\n",
            "Hi , I am Tushar from Hackveda . In this video i have brought to you , A Simple PDF File This is a small demonstration .pdf file - just for use in the Virtual Mechanics tutorials . More text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . Boring , zzzzz . And more text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . Even more . Continued on page 2 ...\n",
            "CreateImage result [{'cmd': ['java', '-jar', '/usr/local/lib/python3.7/dist-packages/pdf2jpg/pdf2jpg.jar', '-i', '/content/sample.pdf', '-o', '/content/Tushar/images', '-d', '300', '-p', '0'], 'input_path': '/content/sample.pdf', 'output_pdfpath': '/content/Tushar/images/sample.pdf_dir', 'output_jpgfiles': ['/content/Tushar/images/sample.pdf_dir/0_sample.pdf.jpg']}]\n",
            "None\n",
            "['0_sample.pdf.jpg']\n",
            "Test 0_sample.pdf.jpg\n",
            "2550 3300\n",
            "/content/Tushar/images/sample.pdf_dir/0_sample.pdf.jpg  is resized\n",
            "Adding  0_sample.pdf.jpg  to video\n",
            "Video ready /content/Tushar/video/0.mp4\n",
            "[MoviePy] >>>> Building video /content/Tushar_final/Lesson 1-Tushar.mp4\n",
            "[MoviePy] Writing audio in Lesson 1-TusharTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1381/1381 [00:03<00:00, 390.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] Writing video /content/Tushar_final/Lesson 1-Tushar.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/moviepy/video/io/ffmpeg_reader.py:130: UserWarning: Warning: in file /content/Tushar/video/0.mp4, 25245000 bytes wanted but 0 bytes read,at frame 1/2, at time 0.02/0.02 sec. Using the last valid frame instead.\n",
            "  UserWarning)\n",
            "\n",
            "100%|██████████| 2/2 [00:00<00:00, 17.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] >>>> Video ready: /content/Tushar_final/Lesson 1-Tushar.mp4 \n",
            "\n",
            "Simple PDF File 2 ... continued from page 1 . Yet more text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . Oh , how boring typing this stuff . But not as boring as watching paint dry . And more text . And more text . And more text . And more text . Boring . More , a little more text . The end , and just as well .\n",
            "Thanks for watching. See you in the next video.\n",
            "Simple PDF File 2 ... continued from page 1 . Yet more text . And more text . And more text . And more text . And more text . And more text . And more text . And more text . Oh , how boring typing this stuff . But not as boring as watching paint dry . And more text . And more text . And more text . And more text . Boring . More , a little more text . The end , and just as well . Thanks for watching . See you in the next video .\n",
            "CreateImage result [{'cmd': ['java', '-jar', '/usr/local/lib/python3.7/dist-packages/pdf2jpg/pdf2jpg.jar', '-i', '/content/sample.pdf', '-o', '/content/Tushar/images', '-d', '300', '-p', '1'], 'input_path': '/content/sample.pdf', 'output_pdfpath': '/content/Tushar/images/sample.pdf_dir', 'output_jpgfiles': ['/content/Tushar/images/sample.pdf_dir/1_sample.pdf.jpg']}]\n",
            "None\n",
            "['1_sample.pdf.jpg']\n",
            "Test 1_sample.pdf.jpg\n",
            "2550 3300\n",
            "/content/Tushar/images/sample.pdf_dir/1_sample.pdf.jpg  is resized\n",
            "Adding  1_sample.pdf.jpg  to video\n",
            "Video ready /content/Tushar/video/1.mp4\n",
            "[MoviePy] >>>> Building video /content/Tushar_final/Lesson 2-Tushar.mp4\n",
            "[MoviePy] Writing audio in Lesson 2-TusharTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 863/863 [00:02<00:00, 397.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] Writing video /content/Tushar_final/Lesson 2-Tushar.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/moviepy/video/io/ffmpeg_reader.py:130: UserWarning: Warning: in file /content/Tushar/video/1.mp4, 25245000 bytes wanted but 0 bytes read,at frame 1/2, at time 0.02/0.02 sec. Using the last valid frame instead.\n",
            "  UserWarning)\n",
            "\n",
            "100%|██████████| 2/2 [00:00<00:00, 30.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] >>>> Video ready: /content/Tushar_final/Lesson 2-Tushar.mp4 \n",
            "\n"
          ]
        }
      ]
    }
  ]
}